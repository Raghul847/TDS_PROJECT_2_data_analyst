#!/usr/bin/env python3
"""
Backend Test Suite for Data Analyst Agent - Non-LLM Components
Tests backend functionality that doesn't require LLM integration
"""

import requests
import json
import time
import tempfile
import os
import pandas as pd
from pathlib import Path

# Get backend URL from frontend .env
BACKEND_URL = "https://6e29e858-c0aa-4254-8f4b-48a71736359d.preview.emergentagent.com/api"

class DataAnalystBasicTester:
    def __init__(self):
        self.backend_url = BACKEND_URL
        self.test_results = []
        
    def log_test(self, test_name, success, details):
        """Log test results"""
        result = {
            "test": test_name,
            "success": success,
            "details": details
        }
        self.test_results.append(result)
        status = "‚úÖ PASS" if success else "‚ùå FAIL"
        print(f"{status} {test_name}: {details}")
        print()

    def test_health_endpoint(self):
        """Test the health check endpoint"""
        try:
            response = requests.get(f"{self.backend_url}/health", timeout=10)
            if response.status_code == 200:
                data = response.json()
                if data.get("status") == "healthy":
                    self.log_test("Health Check", True, "Backend is healthy and responding")
                    return True
                else:
                    self.log_test("Health Check", False, f"Unexpected health response: {data}")
                    return False
            else:
                self.log_test("Health Check", False, f"Health endpoint returned {response.status_code}")
                return False
        except Exception as e:
            self.log_test("Health Check", False, f"Health endpoint failed: {str(e)}")
            return False

    def test_multipart_form_data_acceptance(self):
        """Test that the API accepts multipart form data"""
        try:
            # Create a simple questions file
            temp_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
            temp_file.write("Simple test question")
            temp_file.close()
            
            with open(temp_file.name, 'rb') as qf:
                files = {
                    'questions': ('questions.txt', qf, 'text/plain')
                }
                
                response = requests.post(f"{self.backend_url}/", files=files, timeout=30)
            
            # Clean up
            os.unlink(temp_file.name)
            
            # We expect this to fail due to OpenAI quota, but it should accept the multipart data
            if response.status_code == 200:
                data = response.json()
                if data.get("status") == "error" and "quota" in str(data.get("error", "")).lower():
                    self.log_test("Multipart Form Data", True, 
                                "API correctly accepts multipart form data (fails at LLM step as expected)")
                    return True
                else:
                    self.log_test("Multipart Form Data", True, 
                                f"API accepts multipart data, status: {data.get('status')}")
                    return True
            else:
                self.log_test("Multipart Form Data", False, 
                            f"API returned {response.status_code}: {response.text}")
                return False
                
        except Exception as e:
            self.log_test("Multipart Form Data", False, f"Test failed with error: {str(e)}")
            return False

    def test_file_upload_processing(self):
        """Test that files are properly uploaded and processed"""
        try:
            # Create test CSV file
            data = {'Name': ['Alice', 'Bob'], 'Age': [25, 30]}
            df = pd.DataFrame(data)
            csv_file = tempfile.NamedTemporaryFile(mode='w', suffix='.csv', delete=False)
            df.to_csv(csv_file.name, index=False)
            csv_file.close()
            
            # Create questions file
            questions_file = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
            questions_file.write("Analyze the CSV data")
            questions_file.close()
            
            with open(questions_file.name, 'rb') as qf, open(csv_file.name, 'rb') as cf:
                files = {
                    'questions': ('questions.txt', qf, 'text/plain'),
                    'files': ('test_data.csv', cf, 'text/csv')
                }
                
                response = requests.post(f"{self.backend_url}/", files=files, timeout=30)
            
            # Clean up
            os.unlink(questions_file.name)
            os.unlink(csv_file.name)
            
            if response.status_code == 200:
                data = response.json()
                # Should fail at LLM step but files should be processed
                if data.get("status") == "error" and "quota" in str(data.get("error", "")).lower():
                    self.log_test("File Upload Processing", True, 
                                "Files uploaded and processed correctly (fails at LLM step as expected)")
                    return True
                else:
                    self.log_test("File Upload Processing", True, 
                                f"Files processed, status: {data.get('status')}")
                    return True
            else:
                self.log_test("File Upload Processing", False, 
                            f"API returned {response.status_code}: {response.text}")
                return False
                
        except Exception as e:
            self.log_test("File Upload Processing", False, f"Test failed with error: {str(e)}")
            return False

    def test_error_handling(self):
        """Test error handling with invalid inputs"""
        try:
            # Test with missing questions file
            response = requests.post(f"{self.backend_url}/", files={}, timeout=30)
            
            if response.status_code == 422:  # FastAPI validation error
                self.log_test("Error Handling", True, 
                            "Correctly returned validation error for missing questions file")
                return True
            else:
                self.log_test("Error Handling", False, 
                            f"Expected 422 validation error, got {response.status_code}")
                return False
                
        except Exception as e:
            self.log_test("Error Handling", False, f"Test failed with error: {str(e)}")
            return False

    def test_database_endpoint(self):
        """Test database tasks endpoint"""
        try:
            response = requests.get(f"{self.backend_url}/tasks", timeout=30)
            
            if response.status_code == 200:
                tasks = response.json()
                if isinstance(tasks, list):
                    self.log_test("Database Endpoint", True, 
                                f"Tasks endpoint working, returned {len(tasks)} tasks")
                    return True
                else:
                    self.log_test("Database Endpoint", False, 
                                f"Tasks endpoint returned invalid data type: {type(tasks)}")
                    return False
            else:
                self.log_test("Database Endpoint", False, 
                            f"Tasks endpoint returned {response.status_code}")
                return False
                
        except Exception as e:
            self.log_test("Database Endpoint", False, f"Test failed with error: {str(e)}")
            return False

    def run_basic_tests(self):
        """Run basic backend tests that don't require LLM"""
        print("üöÄ Starting Data Analyst Agent Basic Backend Tests")
        print(f"Backend URL: {self.backend_url}")
        print("Note: LLM-dependent tests skipped due to OpenAI quota exceeded")
        print("=" * 60)
        
        tests = [
            ("Health Check", self.test_health_endpoint),
            ("Multipart Form Data Acceptance", self.test_multipart_form_data_acceptance),
            ("File Upload Processing", self.test_file_upload_processing),
            ("Error Handling", self.test_error_handling),
            ("Database Endpoint", self.test_database_endpoint),
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            print(f"Running: {test_name}")
            if test_func():
                passed += 1
        
        print("=" * 60)
        print(f"üìä Basic Test Results: {passed}/{total} tests passed")
        
        return self.test_results

if __name__ == "__main__":
    tester = DataAnalystBasicTester()
    results = tester.run_basic_tests()